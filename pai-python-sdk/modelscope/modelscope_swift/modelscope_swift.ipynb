{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 通过PAI Python SDK使用Swift微调和部署大语言模型\n",
    "\n",
    "\n",
    "[ModelScope Swift](https://github.com/modelscope/swift) 是 ModelScope 社区开发的高效微调训练和推理框架，他支持一系列的先进的开源大语言模型的微调训练和部署，包括 `Qwen`，`Mixtral`，`Baichuan`，`ChatGLM`，`LLama2`等，开发者可以通过数行代码即可完成大语言模型的微调和部署。\n",
    "\n",
    "在当前文档中，我们将以[Qwen-7B-Chat](https://modelscope.cn/models/qwen/Qwen-7B-Chat/summary) 模型为示例，展示如何通过[PAI Python SDK](https://alipai.readthedocs.io/)在PAI平台上使用ModelScope Swift进行微调训练和模型部署。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前提准备\n",
    "\n",
    "\n",
    "安装PAI Python SDK，用于提交任务或是部署推理服务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装PAI Python SDK\n",
    "!python -m pip install -U \"alipai\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "SDK需要配置访问阿里云服务需要的AccessKey，以及当前使用的工作空间和OSS Bucket。在PAI SDK安装之后，通过在**命令行终端** 中执行以下命令，按照引导配置密钥、工作空间等信息。\n",
    "\n",
    "\n",
    "```shell\n",
    "\n",
    "# 以下命令，请在 \"命令行终端\" 中执行.\n",
    "\n",
    "python -m pai.toolkit.config\n",
    "\n",
    "```\n",
    "\n",
    "我们可以执行以下代码，验证配置是否成功。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.5.post1\n"
     ]
    }
   ],
   "source": [
    "import pai\n",
    "from pai.session import get_default_session, setup_default_session\n",
    "\n",
    "print(pai.__version__)\n",
    "\n",
    "sess = get_default_session()\n",
    "\n",
    "# 用户也可以通过代码方式配置AK/SK/Region/WorkspaceId等信息\n",
    "# if not sess:\n",
    "#     sess = setup_default_session(\n",
    "#         access_key_id=\"<your-access-key-id>\",\n",
    "#         access_key_secret=\"<your-access-key-secret>\",\n",
    "#         region_id=\"<region-id>\",\n",
    "#         workspace_id=\"<workspace-id>\",\n",
    "#         oss_bucket_name=\"<oss-bucket-name>\",\n",
    "#     )\n",
    "#     sess.save_config()\n",
    "\n",
    "\n",
    "# 配置成功之后，我们可以拿到工作空间的信息\n",
    "assert sess is not None\n",
    "assert sess.workspace_name is not None\n",
    "assert sess.oss_bucket is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 模型微调训练\n",
    "\n",
    "Swifit对常见的大语言模型提供了开箱即用的参数配置和脚本，支持LoRA，全参数等方式对模型进行微调训练。\n",
    "例如以下Swift提供的微调训练脚本，将使用`ms-agent`数据集，对`Qwen-7B-Chat`模型进行LoRA微调训练。\n",
    "\n",
    "```shell\n",
    "# source: https://github.com/modelscope/swift/blob/main/examples/pytorch/llm/scripts/qwen_7b_chat/lora/sft.sh\n",
    "\n",
    "PYTHONPATH=../../.. \\\n",
    "python llm_sft.py \\\n",
    "    --model_id_or_path qwen/Qwen-7B-Chat \\\n",
    "    --model_revision master \\\n",
    "    --sft_type lora \\\n",
    "    --tuner_backend swift \\\n",
    "    --template_type qwen \\\n",
    "    --dtype AUTO \\\n",
    "    --output_dir output \\\n",
    "    --dataset ms-agent \\\n",
    "    --use_loss_scale true \\\n",
    "    --train_dataset_mix_ratio 2.0 \\\n",
    "    --train_dataset_sample -1 \\\n",
    "    --num_train_epochs 1 \\\n",
    "    --max_length 2048 \\\n",
    "    --check_dataset_strategy warning \\\n",
    "    --lora_rank 8 \\\n",
    "    --lora_alpha 32 \\\n",
    "    --lora_dropout_p 0.05 \\\n",
    "    --lora_target_modules ALL \\\n",
    "    --gradient_checkpointing true \\\n",
    "    --batch_size 1 \\\n",
    "    --weight_decay 0.01 \\\n",
    "    --learning_rate 1e-4 \\\n",
    "    --gradient_accumulation_steps 16 \\\n",
    "    --max_grad_norm 0.5 \\\n",
    "    --warmup_ratio 0.03 \\\n",
    "    --eval_steps 100 \\\n",
    "    --save_steps 100 \\\n",
    "    --save_total_limit 2 \\\n",
    "    --logging_steps 10 \\\n",
    "    --use_flash_attn false \\\n",
    "    --self_cognition_sample 3000 \\\n",
    "    --model_name 卡卡罗特 \\\n",
    "    --model_author 陶白白 \\\n",
    "    --push_to_hub false \\\n",
    "    --hub_model_id qwen-7b-chat-lora \\\n",
    "    --hub_private_repo true \\\n",
    "    --hub_token 'your-sdk-token'\n",
    "\n",
    "```\n",
    "\n",
    "以上命令中的参数详解，用户可以参考Swift文档：[支持的模型和数据集文档](https://github.com/modelscope/swift/blob/main/docs/source/LLM/%E6%94%AF%E6%8C%81%E7%9A%84%E6%A8%A1%E5%9E%8B%E5%92%8C%E6%95%B0%E6%8D%AE%E9%9B%86.md)，[微调参数详解文档](https://github.com/modelscope/swift/blob/main/docs/source/LLM/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0.md)。\n",
    "\n",
    "### 使用PAI Python SDK提交微调训练任务\n",
    "\n",
    "通过PAI Python SDK提供的`ModelScopeEstimator`对象，用户可以方便得使用PAI提供的镜像提交训练作业。预置镜像中安装了基础的依赖库，包括`ModelScope`, `Swift`, `PyTorch`等，使用`ModelScopeEstimator`，用户可以轻松得在PAI上使用Swift框架完成模型微调训练。\n",
    "\n",
    "\n",
    "以下代码中，我们基于Swift提供的`Qwen-7B-Chat`模型的[LoRA训练脚本](https://github.com/modelscope/swift/blob/main/examples/pytorch/llm/scripts/qwen_7b_chat/lora/sft.sh)提供的训练参数，通过PAI Python SDK提交训练任务。\n",
    "\n",
    "在代码中，我们通过`hyerparameters`参数，将训练参数传递给到训练作业，然后在启动命令中，使用环境变量的方式引用这些参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pai.modelscope import ModelScopeEstimator\n",
    "\n",
    "# 通过 git_config 指定训练脚本相关的 git 地址和分支\n",
    "git_config = {\"repo\": \"https://github.com/modelscope/swift.git\", \"branch\": \"v1.5.3\"}\n",
    "\n",
    "# Swift的LLM SFT的完整参数支持，请参考：\n",
    "# https://github.com/modelscope/swift/blob/main/docs/source/LLM/%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%8F%82%E6%95%B0.md#sft-%E5%8F%82%E6%95%B0\n",
    "hyperparameters = {\n",
    "    \"model_id_or_path\": \"qwen/Qwen-7B-Chat\",\n",
    "    \"model_revision\": \"master\",\n",
    "    \"sft_type\": \"lora\",\n",
    "    \"tuner_backend\": \"swift\",\n",
    "    \"template_type\": \"qwen\",\n",
    "    \"dtype\": \"AUTO\",\n",
    "    \"dataset\": \"blossom-math-zh\",\n",
    "    \"train_dataset_sample\": -1,\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"max_length\": 2048,\n",
    "    \"check_dataset_strategy\": \"warning\",\n",
    "    \"lora_rank\": 8,\n",
    "    \"lora_alpha\": 32,\n",
    "    \"lora_dropout_p\": \"0.05\",\n",
    "    \"lora_target_modules\": \"DEFAULT\",\n",
    "    \"gradient_checkpointing\": \"true\",\n",
    "    \"batch_size\": \"1\",\n",
    "    \"weight_decay\": \"0.01\",\n",
    "    \"learning_rate\": \"1e-4\",\n",
    "    \"gradient_accumulation_steps\": \"16\",\n",
    "    \"max_grad_norm\": \"0.5\",\n",
    "    \"warmup_ratio\": \"0.03\",\n",
    "    \"eval_steps\": \"100\",\n",
    "    \"save_steps\": \"100\",\n",
    "    \"save_total_limit\": \"2\",\n",
    "    \"logging_steps\": \"10\",\n",
    "    \"use_flash_attn\": \"false\",\n",
    "}\n",
    "\n",
    "# 训练作业需要需要配置训练输出路径\n",
    "hyperparameters.update(\n",
    "    {\n",
    "        # 模型输出地址，请勿修改\n",
    "        \"output_dir\": \"/ml/output/model/\",\n",
    "        \"add_output_dir_suffix\": \"false\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 ModelScopeEstimator 对象\n",
    "est = ModelScopeEstimator(\n",
    "    # 指定训练脚本的启动命令，通过 $PAI_USER_ARGS 环境变量传入所有超参信息\n",
    "    command=\"swift sft $PAI_USER_ARGS\",\n",
    "    # instance_type=\"ecs.gn6e-c12g1.3xlarge\",  # 1xV100 GPU (32GB显存)\n",
    "    instance_type=\"ecs.gn7e-c16g1.4xlarge\",\n",
    "    # 用于选择训练镜像\n",
    "    modelscope_version=\"1.11.0\",\n",
    "    hyperparameters=hyperparameters,\n",
    "    base_job_name=\"modelscope-sdk-train\",\n",
    ")\n",
    "\n",
    "# 提交训练作业，默认等待到训练终止（成功或是失败）。\n",
    "est.fit()\n",
    "\n",
    "# 查看训练任务所产出的模型地址，用户可以通过ossutils，或是其他方式下载模型到本地.\n",
    "print(est.model_data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上训练作业中，我们通过`--dataset`参数，使用了预置的数据集`blossom-math-zh`，Swift框架将自动完成数据集的下载准备工作。\n",
    "\n",
    "Swift也支持使用自定义数据集完成微调训练，通过`--custom_train_dataset_path`和`--custom_val_dataset_path`参数，用户可以指定自定义数据集的路径，具体介绍可以参考Swift的文档：[自定义数据集微调训练](https://github.com/modelscope/swift/blob/main/docs/source/LLM/%E8%87%AA%E5%AE%9A%E4%B9%89%E4%B8%8E%E6%8B%93%E5%B1%95.md#%E8%87%AA%E5%AE%9A%E4%B9%89%E6%95%B0%E6%8D%AE%E9%9B%86)\n",
    "\n",
    "当开发者使用`ModelScopeEstimator`在PAI提交训练作业时，支持在训练作业中使用OSS、NAS、MaxCompute表等数据源。通过`fit`方法的`inputs`参数，我们可以指定训练使用的数据集的路径，相应的数据会被准备到训练作业环境中，支持训练作业直接读取使用，具体可以参考文档：[使用训练数据](https://alipai.readthedocs.io/zh/latest/user-guide/training/use-data.html)\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "from pai.modelscope import ModelScopeEstimator\n",
    "\n",
    "\n",
    "hps = {\n",
    "\t\"custom_train_dataset_path\": \"/ml/input/data/train/<TRAIN_FILE_NAME>\",\n",
    "\t\"custom_val_dataset_path\": \"/ml/input/data/validation/<VALIDATION_FILE_NAME>\",\n",
    "\t# more parameters\n",
    "\t# ...\n",
    "}\n",
    "est = ModelScopeEstimator(\n",
    "\t# 通过 --custom_train_dataset_path 和 --custom_val_dataset_path 参数，传递数据集路径\n",
    "\tcommand=\"python llm_sft.py $PAI_USER_ARGS\",\n",
    "\t# more parameters...\n",
    ")\n",
    "\n",
    "\n",
    "# 使用自定义数据集微调训练\n",
    "est.fit(\n",
    "\tinputs={\n",
    "\t\t# 可以使用本地路径或者OSS路径，相应的数据集会被准备到 /ml/input/data/{channel_name}/ 路径下.\n",
    "\t\t\"train\": \"oss://<YourOssBucketName>/<PathToTrainData>\",\n",
    "\t\t# 本地文件会被上传到OSS Bucket，然后再被挂载到训练作业中。\n",
    "\t\t\"validation\": \"/path/to/validation/data\",\n",
    "\t}\n",
    ")\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型部署\n",
    "\n",
    "Swift支持将微调获得的模型部署为在线推理服务，具体介绍可以参考文档：[Swift：vLLM推理加速与部署](https://github.com/modelscope/swift/blob/main/docs/source/LLM/VLLM%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F%E4%B8%8E%E9%83%A8%E7%BD%B2.md#%E9%83%A8%E7%BD%B2)。在本章节中，我们将通过 PAI Python SDK 将训练产出的模型部署到 PAI-EAS，创建在线推理服务。\n",
    "\n",
    "\n",
    "### 下载合并模型\n",
    "\n",
    "在模型部署之前，我们需要将微调训练获得的LoRA模型下载到本地，与原始模型合并获得完整的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/pai/common/oss_utils.py:30: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n",
      "Downloading file: ./qwen-lora-model/checkpoint-600/README.md: 100%|██████████| 125/125 [00:00<00:00, 2.39kB/s]<?, ?it/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-600/configuration.json: 100%|██████████| 358/358 [00:00<00:00, 9.42kB/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-600/default/adapter_config.json: 100%|██████████| 655/655 [00:00<00:00, 9.47kB/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-600/default/adapter_model.safetensors: 100%|██████████| 16.8M/16.8M [00:00<00:00, 31.1MB/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-600/generation_config.json: 100%|██████████| 275/275 [00:00<00:00, 7.31kB/s]it/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-600/optimizer.pt: 100%|██████████| 33.6M/33.6M [00:00<00:00, 50.2MB/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-600/qwen.tiktoken: 100%|██████████| 2.56M/2.56M [00:00<00:00, 14.3MB/s] 3.59it/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-600/rng_state.pth: 100%|██████████| 14.2k/14.2k [00:00<00:00, 153kB/s]  3.91it/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-600/scheduler.pt: 100%|██████████| 1.06k/1.06k [00:00<00:00, 20.6kB/s]  4.64it/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-600/sft_args.json: 100%|██████████| 2.72k/2.72k [00:00<00:00, 19.4kB/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-600/special_tokens_map.json: 100%|██████████| 61.0/61.0 [00:00<00:00, 1.20kB/s]/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-600/tokenization_qwen.py: 100%|██████████| 9.62k/9.62k [00:00<00:00, 89.9kB/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-600/tokenizer_config.json: 100%|██████████| 299/299 [00:00<00:00, 2.86kB/s]28it/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-600/trainer_state.json: 100%|██████████| 10.9k/10.9k [00:00<00:00, 67.9kB/s]7it/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-600/training_args.bin: 100%|██████████| 6.46k/6.46k [00:00<00:00, 116kB/s].15it/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-618/README.md: 100%|██████████| 125/125 [00:00<00:00, 2.39kB/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-618/configuration.json: 100%|██████████| 358/358 [00:00<00:00, 19.9kB/s] 8.80it/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-618/default/adapter_config.json: 100%|██████████| 655/655 [00:00<00:00, 8.28kB/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-618/default/adapter_model.safetensors: 100%|██████████| 16.8M/16.8M [00:00<00:00, 53.2MB/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-618/generation_config.json: 100%|██████████| 275/275 [00:00<00:00, 2.11kB/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-618/optimizer.pt: 100%|██████████| 33.6M/33.6M [00:00<00:00, 52.9MB/s],  7.18it/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-618/qwen.tiktoken: 100%|██████████| 2.56M/2.56M [00:00<00:00, 11.6MB/s]  4.20it/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-618/rng_state.pth: 100%|██████████| 14.2k/14.2k [00:00<00:00, 167kB/s],  4.21it/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-618/scheduler.pt: 100%|██████████| 1.06k/1.06k [00:00<00:00, 8.77kB/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-618/sft_args.json: 100%|██████████| 2.72k/2.72k [00:00<00:00, 31.6kB/s]  5.29it/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-618/special_tokens_map.json: 100%|██████████| 61.0/61.0 [00:00<00:00, 896B/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-618/tokenization_qwen.py: 100%|██████████| 9.62k/9.62k [00:00<00:00, 113kB/s]it/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-618/tokenizer_config.json: 100%|██████████| 299/299 [00:00<00:00, 5.53kB/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-618/trainer_state.json: 100%|██████████| 11.3k/11.3k [00:00<00:00, 90.7kB/s]0it/s]\n",
      "Downloading file: ./qwen-lora-model/checkpoint-618/training_args.bin: 100%|██████████| 6.46k/6.46k [00:00<00:00, 84.5kB/s]83it/s]\n",
      "Downloading file: ./qwen-lora-model/images/eval_acc.png: 100%|██████████| 26.2k/26.2k [00:00<00:00, 333kB/s]\n",
      "Downloading file: ./qwen-lora-model/images/eval_loss.png: 100%|██████████| 18.4k/18.4k [00:00<00:00, 181kB/s]04<00:01,  8.76it/s]\n",
      "Downloading file: ./qwen-lora-model/images/eval_runtime.png: 100%|██████████| 19.7k/19.7k [00:00<00:00, 211kB/s]00:01,  8.88it/s]\n",
      "Downloading file: ./qwen-lora-model/images/eval_samples_per_second.png: 100%|██████████| 26.4k/26.4k [00:00<00:00, 193kB/s]7it/s]\n",
      "Downloading file: ./qwen-lora-model/images/eval_steps_per_second.png: 100%|██████████| 25.8k/25.8k [00:00<00:00, 192kB/s].43it/s]\n",
      "Downloading file: ./qwen-lora-model/images/train_acc.png: 100%|██████████| 28.7k/28.7k [00:00<00:00, 399kB/s]05<00:01,  8.08it/s]\n",
      "Downloading file: ./qwen-lora-model/images/train_epoch.png: 100%|██████████| 18.7k/18.7k [00:00<00:00, 188kB/s]\n",
      "Downloading file: ./qwen-lora-model/images/train_learning_rate.png: 100%|██████████| 25.4k/25.4k [00:00<00:00, 225kB/s] 9.09it/s]\n",
      "Downloading file: ./qwen-lora-model/images/train_loss.png: 100%|██████████| 24.1k/24.1k [00:00<00:00, 177kB/s]5<00:01,  8.89it/s]\n",
      "Downloading file: ./qwen-lora-model/images/train_total_flos.png: 100%|██████████| 12.6k/12.6k [00:00<00:00, 127kB/s]1,  8.18it/s]\n",
      "Downloading file: ./qwen-lora-model/images/train_train_loss.png: 100%|██████████| 11.7k/11.7k [00:00<00:00, 133kB/s]0,  8.44it/s]\n",
      "Downloading file: ./qwen-lora-model/images/train_train_runtime.png: 100%|██████████| 13.8k/13.8k [00:00<00:00, 187kB/s]\n",
      "Downloading file: ./qwen-lora-model/images/train_train_samples_per_second.png: 100%|██████████| 17.5k/17.5k [00:00<00:00, 191kB/s]\n",
      "Downloading file: ./qwen-lora-model/images/train_train_steps_per_second.png: 100%|██████████| 14.8k/14.8k [00:00<00:00, 271kB/s]]\n",
      "Downloading file: ./qwen-lora-model/logging.jsonl: 100%|██████████| 7.68k/7.68k [00:00<00:00, 96.9kB/s]\n",
      "Downloading file: ./qwen-lora-model/runs/events.out.tfevents.1707147764.trainb1y4g5b473j-master-0.11.0: 100%|██████████| 21.6k/21.6k [00:00<00:00, 212kB/s]\n",
      "Downloading file: ./qwen-lora-model/sft_args.json: 100%|██████████| 2.72k/2.72k [00:00<00:00, 24.6kB/s]\n",
      "Downloading file: ./qwen-lora-model/training_args.json: 100%|██████████| 4.23k/4.23k [00:00<00:00, 82.4kB/s]:06<00:00,  9.78it/s]\n",
      "Downloading: pai/training_job/modelscope_sdk_train_20240205_233710_7p4x8h/model/: 100%|██████████| 48/48 [00:06<00:00,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./qwen-lora-model/checkpoint-618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pai.common.oss_utils import download\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "# 下载模型到本地\n",
    "local_model_dir = download(est.model_data(), \"./qwen-lora-model\")\n",
    "\n",
    "\n",
    "# 获取模型的最新的一个checkpoint用于部署\n",
    "checkpoint_dirs = glob.glob(os.path.join(local_model_dir, \"checkpoint-*\"))\n",
    "latest_version = max(int(os.path.basename(d).split(\"-\")[1]) for d in checkpoint_dirs)\n",
    "latest_checkpoint_dir = os.path.join(local_model_dir, f\"checkpoint-{latest_version}\")\n",
    "\n",
    "print(latest_checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "以下代码中，我们将使用Swift提供的命令行工具，将训练获得的LoRA模型和原始的模型合并，获得完整的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Requirement already satisfied: ms-swift in /opt/conda/lib/python3.10/site-packages (1.5.1)\n",
      "Collecting ms-swift\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/ac/0b/b1eb10eb44764293ee5c2bfe74247c4712f93c921cc6af282388ee2ec0b7/ms_swift-1.5.4-py3-none-any.whl (340 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m340.6/340.6 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from ms-swift) (0.25.0)\n",
      "Requirement already satisfied: dacite in /opt/conda/lib/python3.10/site-packages (from ms-swift) (1.8.1)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from ms-swift) (2.16.1)\n",
      "Requirement already satisfied: jieba in /opt/conda/lib/python3.10/site-packages (from ms-swift) (0.42.1)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from ms-swift) (3.5.3)\n",
      "Requirement already satisfied: modelscope>=1.9.3 in /opt/conda/lib/python3.10/site-packages (from ms-swift) (1.11.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from ms-swift) (3.8.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from ms-swift) (1.26.3)\n",
      "Requirement already satisfied: optimum in /opt/conda/lib/python3.10/site-packages (from ms-swift) (1.16.1)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from ms-swift) (2.1.4)\n",
      "Requirement already satisfied: peft<0.8.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from ms-swift) (0.7.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from ms-swift) (2.31.0)\n",
      "Requirement already satisfied: rouge in /opt/conda/lib/python3.10/site-packages (from ms-swift) (1.0.1)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from ms-swift) (0.4.1)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (from ms-swift) (2.15.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from ms-swift) (4.65.0)\n",
      "Requirement already satisfied: transformers<4.38,>=4.33 in /opt/conda/lib/python3.10/site-packages (from ms-swift) (4.37.2)\n",
      "Requirement already satisfied: trl>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from ms-swift) (0.7.7)\n",
      "Requirement already satisfied: addict in /opt/conda/lib/python3.10/site-packages (from modelscope>=1.9.3->ms-swift) (2.4.0)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.10/site-packages (from modelscope>=1.9.3->ms-swift) (23.2.0)\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from modelscope>=1.9.3->ms-swift) (0.7.0)\n",
      "Requirement already satisfied: filelock>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from modelscope>=1.9.3->ms-swift) (3.13.1)\n",
      "Requirement already satisfied: gast>=0.2.2 in /opt/conda/lib/python3.10/site-packages (from modelscope>=1.9.3->ms-swift) (0.5.4)\n",
      "Requirement already satisfied: oss2 in /opt/conda/lib/python3.10/site-packages (from modelscope>=1.9.3->ms-swift) (2.18.4)\n",
      "Requirement already satisfied: Pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from modelscope>=1.9.3->ms-swift) (10.2.0)\n",
      "Requirement already satisfied: pyarrow!=9.0.0,>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from modelscope>=1.9.3->ms-swift) (14.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.10/site-packages (from modelscope>=1.9.3->ms-swift) (2.8.2)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from modelscope>=1.9.3->ms-swift) (6.0.1)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from modelscope>=1.9.3->ms-swift) (1.11.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from modelscope>=1.9.3->ms-swift) (68.0.0)\n",
      "Requirement already satisfied: simplejson>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from modelscope>=1.9.3->ms-swift) (3.19.2)\n",
      "Requirement already satisfied: sortedcontainers>=1.5.9 in /opt/conda/lib/python3.10/site-packages (from modelscope>=1.9.3->ms-swift) (2.4.0)\n",
      "Requirement already satisfied: urllib3>=1.26 in /opt/conda/lib/python3.10/site-packages (from modelscope>=1.9.3->ms-swift) (1.26.16)\n",
      "Requirement already satisfied: yapf in /opt/conda/lib/python3.10/site-packages (from modelscope>=1.9.3->ms-swift) (0.30.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets->ms-swift) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets->ms-swift) (0.3.7)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->ms-swift) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->ms-swift) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets->ms-swift) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->ms-swift) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets->ms-swift) (0.20.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets->ms-swift) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft<0.8.0,>=0.7.1->ms-swift) (5.9.7)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft<0.8.0,>=0.7.1->ms-swift) (2.1.2+cu121)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->ms-swift) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->ms-swift) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->ms-swift) (2023.11.17)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<4.38,>=4.33->ms-swift) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<4.38,>=4.33->ms-swift) (0.15.0)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /opt/conda/lib/python3.10/site-packages (from trl>=0.7.7->ms-swift) (0.6.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->ms-swift) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->ms-swift) (4.47.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->ms-swift) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->ms-swift) (3.1.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->ms-swift) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->ms-swift) (1.3.2)\n",
      "Requirement already satisfied: coloredlogs in /opt/conda/lib/python3.10/site-packages (from optimum->ms-swift) (14.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from optimum->ms-swift) (1.12)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->ms-swift) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->ms-swift) (2023.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from rouge->ms-swift) (1.16.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard->ms-swift) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard->ms-swift) (1.60.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard->ms-swift) (2.26.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard->ms-swift) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard->ms-swift) (3.5.1)\n",
      "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard->ms-swift) (3.20.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->ms-swift) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->ms-swift) (2.2.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->ms-swift) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->ms-swift) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->ms-swift) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->ms-swift) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->ms-swift) (4.0.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->ms-swift) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->ms-swift) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->ms-swift) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->ms-swift) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets->ms-swift) (4.9.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft<0.8.0,>=0.7.1->ms-swift) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft<0.8.0,>=0.7.1->ms-swift) (3.1.2)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft<0.8.0,>=0.7.1->ms-swift) (2.1.0)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /opt/conda/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum->ms-swift) (0.1.99)\n",
      "Requirement already satisfied: docstring-parser>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl>=0.7.7->ms-swift) (0.15)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl>=0.7.7->ms-swift) (13.7.0)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /opt/conda/lib/python3.10/site-packages (from tyro>=0.5.11->trl>=0.7.7->ms-swift) (1.6.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->ms-swift) (2.1.3)\n",
      "Requirement already satisfied: humanfriendly>=7.1 in /opt/conda/lib/python3.10/site-packages (from coloredlogs->optimum->ms-swift) (10.0)\n",
      "Requirement already satisfied: crcmod>=1.7 in /opt/conda/lib/python3.10/site-packages (from oss2->modelscope>=1.9.3->ms-swift) (1.7)\n",
      "Requirement already satisfied: pycryptodome>=3.4.7 in /opt/conda/lib/python3.10/site-packages (from oss2->modelscope>=1.9.3->ms-swift) (3.19.1)\n",
      "Requirement already satisfied: aliyun-python-sdk-kms>=2.4.1 in /opt/conda/lib/python3.10/site-packages (from oss2->modelscope>=1.9.3->ms-swift) (2.16.2)\n",
      "Requirement already satisfied: aliyun-python-sdk-core>=2.13.12 in /opt/conda/lib/python3.10/site-packages (from oss2->modelscope>=1.9.3->ms-swift) (2.14.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->optimum->ms-swift) (1.3.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.9.3 in /opt/conda/lib/python3.10/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2->modelscope>=1.9.3->ms-swift) (0.10.0)\n",
      "Requirement already satisfied: cryptography>=2.6.0 in /opt/conda/lib/python3.10/site-packages (from aliyun-python-sdk-core>=2.13.12->oss2->modelscope>=1.9.3->ms-swift) (41.0.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->ms-swift) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->ms-swift) (3.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl>=0.7.7->ms-swift) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl>=0.7.7->ms-swift) (2.17.2)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2->modelscope>=1.9.3->ms-swift) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl>=0.7.7->ms-swift) (0.1.2)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2->modelscope>=1.9.3->ms-swift) (2.21)\n",
      "\u001b[33mDEPRECATION: omegaconf 2.0.6 has a non-standard dependency specifier PyYAML>=5.1.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of omegaconf or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: ms-swift\n",
      "  Attempting uninstall: ms-swift\n",
      "    Found existing installation: ms-swift 1.5.1\n",
      "    Uninstalling ms-swift-1.5.1:\n",
      "      Successfully uninstalled ms-swift-1.5.1\n",
      "Successfully installed ms-swift-1.5.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "run sh: `python /opt/conda/lib/python3.10/site-packages/swift/cli/merge_lora.py --ckpt_dir ./qwen-lora-model/checkpoint-618`\n",
      "2024-02-07 16:33:11,077 - modelscope - INFO - PyTorch version 2.1.2+cu121 Found.\n",
      "2024-02-07 16:33:11,078 - modelscope - INFO - TensorFlow version 2.14.0 Found.\n",
      "2024-02-07 16:33:11,078 - modelscope - INFO - Loading ast index from /root/.cache/modelscope/ast_indexer\n",
      "2024-02-07 16:33:11,105 - modelscope - INFO - Loading done! Current index file version is 1.11.0, with md5 423ce83c894bdb7373dafb61c8f0ca7a and a total number of 953 components indexed\n",
      "2024-02-07 16:33:12.079448: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-02-07 16:33:12.081728: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-07 16:33:12.111968: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-07 16:33:12.112009: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-07 16:33:12.112032: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-07 16:33:12.117418: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-07 16:33:12.117734: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-07 16:33:12.802888: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[INFO:swift] Start time of running main: 2024-02-07 16:33:13.480443\n",
      "[INFO:swift] ckpt_dir: /qwen-lora-model/checkpoint-618\n",
      "[INFO:swift] Setting self.eval_human: True\n",
      "[INFO:swift] Setting overwrite_generation_config: True\n",
      "[INFO:swift] replace_if_exists: True\n",
      "[INFO:swift] merged_lora_path: `/qwen-lora-model/checkpoint-618-merged`\n",
      "[INFO:swift] Setting args.sft_type: 'full'\n",
      "[INFO:swift] Setting args.ckpt_dir: /qwen-lora-model/checkpoint-618-merged\n",
      "[WARNING:modelscope] Using the master branch is fragile, please use it with caution!\n",
      "[INFO:modelscope] Use user-specified model revision: master\n",
      "Try importing flash-attention for faster inference...\n",
      "Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
      "Loading checkpoint shards: 100%|██████████████████| 8/8 [00:06<00:00,  1.26it/s]\n",
      "[INFO:swift] model_config: QWenConfig {\n",
      "  \"_name_or_path\": \"/root/.cache/modelscope/hub/qwen/Qwen-7B-Chat\",\n",
      "  \"architectures\": [\n",
      "    \"QWenLMHeadModel\"\n",
      "  ],\n",
      "  \"attn_dropout_prob\": 0.0,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"configuration_qwen.QWenConfig\",\n",
      "    \"AutoModelForCausalLM\": \"modeling_qwen.QWenLMHeadModel\"\n",
      "  },\n",
      "  \"bf16\": false,\n",
      "  \"emb_dropout_prob\": 0.0,\n",
      "  \"fp16\": true,\n",
      "  \"fp32\": false,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 22016,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layer_norm_epsilon\": 1e-06,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"model_type\": \"qwen\",\n",
      "  \"no_bias\": true,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"onnx_safe\": null,\n",
      "  \"rotary_emb_base\": 10000,\n",
      "  \"rotary_pct\": 1.0,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"softmax_in_fp32\": false,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"tokenizer_class\": \"QWenTokenizer\",\n",
      "  \"transformers_version\": \"4.37.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"use_cache_kernel\": false,\n",
      "  \"use_cache_quantization\": false,\n",
      "  \"use_dynamic_ntk\": true,\n",
      "  \"use_flash_attn\": true,\n",
      "  \"use_logn_attn\": true,\n",
      "  \"vocab_size\": 151936\n",
      "}\n",
      "\n",
      "[INFO:swift] Saving merged weights...\n",
      "[INFO:swift] Successfully merged LoRA and saved in /qwen-lora-model/checkpoint-618-merged.\n",
      "[INFO:swift] End time of running main: 2024-02-07 16:33:50.348610\n",
      "./qwen-lora-model/checkpoint-618-merged\n",
      "config.json\t\t\t  modeling_qwen.py\n",
      "configuration.json\t\t  model.safetensors.index.json\n",
      "configuration_qwen.py\t\t  qwen_generation_utils.py\n",
      "cpp_kernels.py\t\t\t  qwen.tiktoken\n",
      "generation_config.json\t\t  sft_args.json\n",
      "model-00001-of-00004.safetensors  special_tokens_map.json\n",
      "model-00002-of-00004.safetensors  tokenization_qwen.py\n",
      "model-00003-of-00004.safetensors  tokenizer_config.json\n",
      "model-00004-of-00004.safetensors\n"
     ]
    }
   ],
   "source": [
    "# 安装ModelScope Swift\n",
    "!python -m pip install -U ms-swift\n",
    "\n",
    "# 使用Swift merge-lora 工具合并模型\n",
    "!swift merge-lora --ckpt_dir {latest_checkpoint_dir}\n",
    "\n",
    "\n",
    "merged_model_dir = os.path.join(local_model_dir, f\"checkpoint-{latest_version}-merged\")\n",
    "print(merged_model_dir)\n",
    "\n",
    "# 查看合并后的模型\n",
    "!ls {merged_model_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上传模型到OSS Bucket，供后续推理服务加载使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading file: qwen-lora-model/checkpoint-618-merged/configuration_qwen.py: 100%|██████████| 2.35k/2.35k [00:00<00:00, 30.6kB/s]\n",
      "Uploading file: qwen-lora-model/checkpoint-618-merged/model.safetensors.index.json: 100%|██████████| 19.5k/19.5k [00:00<00:00, 864kB/s]\n",
      "Uploading file: qwen-lora-model/checkpoint-618-merged/generation_config.json: 100%|██████████| 275/275 [00:00<00:00, 14.7kB/s]\n",
      "Uploading file: qwen-lora-model/checkpoint-618-merged/model-00001-of-00004.safetensors: 100%|██████████| 4.99G/4.99G [00:30<00:00, 161MB/s] \n",
      "Uploading file: qwen-lora-model/checkpoint-618-merged/modeling_qwen.py: 100%|██████████| 55.6k/55.6k [00:00<00:00, 2.28MB/s]\n",
      "Uploading file: qwen-lora-model/checkpoint-618-merged/configuration.json: 100%|██████████| 76.0/76.0 [00:00<00:00, 3.51kB/s]\n",
      "Uploading file: qwen-lora-model/checkpoint-618-merged/qwen.tiktoken: 100%|██████████| 2.56M/2.56M [00:00<00:00, 30.8MB/s]\n",
      "Uploading file: qwen-lora-model/checkpoint-618-merged/sft_args.json: 100%|██████████| 2.72k/2.72k [00:00<00:00, 41.9kB/s]\n",
      "Uploading file: qwen-lora-model/checkpoint-618-merged/tokenizer_config.json: 100%|██████████| 299/299 [00:00<00:00, 20.3kB/s]\n",
      "Uploading file: qwen-lora-model/checkpoint-618-merged/model-00002-of-00004.safetensors: 100%|██████████| 4.98G/4.98G [00:31<00:00, 160MB/s] \n",
      "Uploading file: qwen-lora-model/checkpoint-618-merged/config.json: 100%|██████████| 1.10k/1.10k [00:00<00:00, 54.9kB/s]\n",
      "Uploading file: qwen-lora-model/checkpoint-618-merged/model-00003-of-00004.safetensors: 100%|██████████| 4.23G/4.23G [00:26<00:00, 162MB/s] \n",
      "Uploading file: qwen-lora-model/checkpoint-618-merged/qwen_generation_utils.py: 100%|██████████| 14.6k/14.6k [00:00<00:00, 704kB/s]\n",
      "Uploading file: qwen-lora-model/checkpoint-618-merged/cpp_kernels.py: 100%|██████████| 1.92k/1.92k [00:00<00:00, 42.6kB/s]\n",
      "Uploading file: qwen-lora-model/checkpoint-618-merged/model-00004-of-00004.safetensors: 100%|██████████| 1.24G/1.24G [00:07<00:00, 159MB/s] \n",
      "Uploading file: qwen-lora-model/checkpoint-618-merged/tokenization_qwen.py: 100%|██████████| 9.62k/9.62k [00:00<00:00, 249kB/s]\n",
      "Uploading file: qwen-lora-model/checkpoint-618-merged/special_tokens_map.json: 100%|██████████| 61.0/61.0 [00:00<00:00, 3.77kB/s]\n"
     ]
    }
   ],
   "source": [
    "from pai.common.oss_utils import upload\n",
    "\n",
    "\n",
    "# 上传模型到当前session的bucket.\n",
    "model_data_uri = upload(\n",
    "    merged_model_dir,\n",
    "    \"modelscope-swift-example/qwen-lora-merged-model/\",\n",
    ")\n",
    "print(model_data_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 部署模型\n",
    "\n",
    "通过SDK提供的`ModelScopeEstimator`对象，用户可以配置部署的模型，镜像，机器实例规格等参数，将模型部署为在线推理服务。\n",
    "\n",
    "以下代码中，我们将使用PAI预置的`vLLM`推理服务镜像，使用Swift部署合并后的模型为一个在线推理服务。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the service detail by accessing the console URI: \n",
      "https://pai.console.aliyun.com/?regionId=cn-hangzhou#/eas/serviceDetail/qwen_7b_chat_v5/detail\n"
     ]
    }
   ],
   "source": [
    "from pai.modelscope import ModelScopeModel\n",
    "from pai.common.utils import random_str\n",
    "\n",
    "m = ModelScopeModel(\n",
    "    # 模型OSS路径，默认会被挂载到 /eas/workspace/model 路径下\n",
    "    model_data=model_data_uri,\n",
    "    # 使PAI提供的vllm推理镜像\n",
    "    image_uri=\"eas-registry-vpc.{}.cr.aliyuncs.com/pai-eas/chat-llm-webui:3.0-vllm\".format(\n",
    "        sess.region_id\n",
    "    ),\n",
    "    # 推理服务执行前安装依赖\n",
    "    requirements=[\"ms-swift>=1.6.0\"],\n",
    "    # 推理服务执行命令\n",
    "    command=\"swift deploy --ckpt_dir /eas/workspace/model/ --port 8000 --host 0.0.0.0\",\n",
    "    port=8000,\n",
    ")\n",
    "\n",
    "predictor = m.deploy(\n",
    "    # 推理服务名称\n",
    "    service_name=\"qwen_7b_chat_{}\".format(random_str(8)),\n",
    "    # 推理服务使用的机器实例\n",
    "    instance_type=\"ecs.gn6e-c12g1.3xlarge\",\n",
    ")\n",
    "\n",
    "print(predictor.service_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调用模型推理服务\n",
    "\n",
    "通过`swift deploy`部署的大语言模型，支持通过OpenAI风格的HTTP API进行调用。开发者可以通过openai SDK（推荐）或是使用`Predictor`提供的`raw_predict`方法调用推理服务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 安装openai SDK.\n",
    "!pip install -q openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是一个人工智能助手，能够回答问题、提供建议、生成代码、聊天等任务，帮助用户解决问题和提高效率。\n",
      "\n",
      "Answer: I am an AI assistant that can answer questions, provide suggestions, generate code, chat, and help users solve problems and improve efficiency."
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "\n",
    "# 获取推理服务的地址和访问密钥\n",
    "endpoint = os.path.join(predictor.internet_endpoint, \"v1\")\n",
    "access_token = predictor.access_token\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    base_url=endpoint,\n",
    "    api_key=access_token,\n",
    ")\n",
    "\n",
    "# 调用流式推理服务接口\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"qwen-7b-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"一句话介绍一下你自己\"},\n",
    "    ],\n",
    "    max_tokens=128,\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in completion:\n",
    "    if not chunk.choices:\n",
    "        continue\n",
    "    content = chunk.choices[0].delta.content\n",
    "    if content:\n",
    "        print(content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用户也可以使用`deploy`方法返回的`predictor`对象，直接调用推理服务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"model\": \"qwen-7b-chat\",\n",
      "    \"choices\": [\n",
      "        {\n",
      "            \"index\": 0,\n",
      "            \"message\": {\n",
      "                \"role\": \"assistant\",\n",
      "                \"content\": \"我是一个人工智能助手，可以回答问题、提供信息、进行对话等。我能够帮助用户解决问题，提供有用的信息和建议，以及进行各种任务。\"\n",
      "            },\n",
      "            \"finish_reason\": \"stop\"\n",
      "        }\n",
      "    ],\n",
      "    \"usage\": {\n",
      "        \"prompt_tokens\": 22,\n",
      "        \"completion_tokens\": 34,\n",
      "        \"total_tokens\": 56\n",
      "    },\n",
      "    \"id\": \"chatcmpl-516695f2072d4d3c9aa4bb7b5a5962f2\",\n",
      "    \"object\": \"chat.completion\",\n",
      "    \"created\": 1707296083\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "resp = predictor.raw_predict(\n",
    "    path=\"/v1/chat/completions\",\n",
    "    method=\"POST\",\n",
    "    data={\n",
    "        \"model\": \"qwen-7b-chat\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": \"一句话介绍一下你自己\"}],\n",
    "    },\n",
    ")\n",
    "print(json.dumps(resp.json(), indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "通过当前文档，我们了解了如何基于PAI Python SDK在PAI上使用ModelScope Swift框架进行模型微调训练和部署。通过PAI Python SDK，开发者可以轻松得使用使用各种开源框架完成模型的开发和部署，包括Swift，TensorFlow，PyTorch，HuggingFace transformers等，开发者可以通过[文档](https://alipai.readthedocs.io/)和[示例仓库](https://github.com/aliyun/pai-examples)了解更多关于PAI Python SDK的使用方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 参考文档\n",
    "\n",
    "- 阿里云机器学习平台PAI: https://www.aliyun.com/product/bigdata/learn\n",
    "\n",
    "- ModelScope Swift文档：https://github.com/modelscope/swift/blob/main/docs/source/GetStarted/%E5%BF%AB%E9%80%9F%E4%BD%BF%E7%94%A8.md\n",
    "\n",
    "- PAI Python SDK文档：https://alipai.readthedocs.io/\n",
    "\n",
    "- PAI示例仓库：https://github.com/aliyun/pai-examples\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
